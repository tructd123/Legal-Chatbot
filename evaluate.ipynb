{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a9e4e0",
   "metadata": {},
   "source": [
    "# ÄÃ¡nh giÃ¡ Legal RAG System vá»›i bá»™ dá»¯ liá»‡u ViBidLQA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410fb7c0",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 1. CÃ i Ä‘áº·t vÃ  import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16191e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.6) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.6) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Using HuggingFace embeddings model: sentence-transformers/all-MiniLM-L6-v2\n",
      "ğŸ”„ Using Google chat model: gemini-2.0-flash\n",
      "ğŸ”„ Äang load vectorstore...\n",
      "âœ… ÄÃ£ load knowledge base thÃ nh cÃ´ng!\n",
      "âœ… Há»‡ thá»‘ng LegalRAG Ä‘Ã£ sáºµn sÃ ng.\n",
      "ğŸ”„ Using Google chat model: gemini-2.0-flash\n",
      "ğŸ”„ Äang load vectorstore...\n",
      "âœ… ÄÃ£ load knowledge base thÃ nh cÃ´ng!\n",
      "âœ… Há»‡ thá»‘ng LegalRAG Ä‘Ã£ sáºµn sÃ ng.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "from legal_rag import LegalRAGSystem\n",
    "\n",
    "# Táº£i biáº¿n mÃ´i trÆ°á»ng (vÃ­ dá»¥: GOOGLE_API_KEY)\n",
    "load_dotenv()\n",
    "\n",
    "# Khá»Ÿi táº¡o há»‡ thá»‘ng RAG\n",
    "rag_system = LegalRAGSystem()\n",
    "if not rag_system.load_knowledge_base():\n",
    "    raise RuntimeError(\"Knowledge base chÆ°a sáºµn sÃ ng. HÃ£y cháº¡y 'python rebuild_kb.py' trÆ°á»›c rá»“i thá»­ láº¡i.\")\n",
    "print(\"âœ… Há»‡ thá»‘ng LegalRAG Ä‘Ã£ sáºµn sÃ ng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62f98ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Táº£i dá»¯ liá»‡u thÃ nh cÃ´ng.\n"
     ]
    }
   ],
   "source": [
    "# Táº£i dá»¯ liá»‡u tá»« cÃ¡c file CSV\n",
    "try:\n",
    "    train = pd.read_csv(\"ViBidLQA/train.csv\")\n",
    "    dev = pd.read_csv(\"ViBidLQA/dev.csv\")\n",
    "    test = pd.read_csv(\"ViBidLQA/test.csv\")\n",
    "    print(\"Táº£i dá»¯ liá»‡u thÃ nh cÃ´ng.\")\n",
    "    test.head()\n",
    "except FileNotFoundError:\n",
    "    print(\"Lá»—i: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c 'ViBidLQA' hoáº·c cÃ¡c file csv. HÃ£y cháº¯c cháº¯n báº¡n Ä‘Ã£ cháº¡y cell Ä‘á»ƒ táº£i vÃ  lÆ°u dá»¯ liá»‡u tá»« Hugging Face trÆ°á»›c Ä‘Ã³.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c42207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u soÌ‚Ì 22/2023/QH15 ÄieÌ‚Ì€u 3...</td>\n",
       "      <td>PhuÌ›oÌ›ng thuÌ›Ìc hai giai Ä‘oaÌ£n moÌ£Ì‚t tuÌi hoÌ‚Ì€...</td>\n",
       "      <td>Ä‘aÌ‚Ìu thaÌ‚Ì€u roÌ£Ì‚ng raÌƒi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...</td>\n",
       "      <td>NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...</td>\n",
       "      <td>ThoÌ‚ng tin veÌ‚Ì€ keÌ‚Ìt quaÌ‰ thuÌ›Ì£c hieÌ£Ì‚n hoÌ›Ì£p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u soÌ‚Ì 22/2023/QH15 ÄieÌ‚Ì€u 2...</td>\n",
       "      <td>LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u soÌ‚Ì 22/2023/QH15 ÄieÌ‚Ì€u 2...</td>\n",
       "      <td>LuÌ›Ì£a choÌ£n nhaÌ€ thaÌ‚Ì€u trong truÌ›oÌ›Ì€ng hoÌ›Ì£p ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...</td>\n",
       "      <td>CaÌ†n cuÌ›Ì phaÌp lyÌ naÌ€o quy Ä‘iÌ£nh veÌ‚Ì€ triÌ€nh...</td>\n",
       "      <td>LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...</td>\n",
       "      <td>Theo NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu t...</td>\n",
       "      <td>laÌ€ vieÌ£Ì‚c mua truÌ›Ì£c tieÌ‚Ìp haÌ€ng hoÌa, diÌ£ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u soÌ‚Ì 22/2023/QH15 ÄieÌ‚Ì€u 3...   \n",
       "1  NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...   \n",
       "2  LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u soÌ‚Ì 22/2023/QH15 ÄieÌ‚Ì€u 2...   \n",
       "3  NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...   \n",
       "4  NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...   \n",
       "\n",
       "                                            question  \\\n",
       "0  PhuÌ›oÌ›ng thuÌ›Ìc hai giai Ä‘oaÌ£n moÌ£Ì‚t tuÌi hoÌ‚Ì€...   \n",
       "1  NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...   \n",
       "2  LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u soÌ‚Ì 22/2023/QH15 ÄieÌ‚Ì€u 2...   \n",
       "3  CaÌ†n cuÌ›Ì phaÌp lyÌ naÌ€o quy Ä‘iÌ£nh veÌ‚Ì€ triÌ€nh...   \n",
       "4  Theo NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu t...   \n",
       "\n",
       "                                              answer  \n",
       "0                           Ä‘aÌ‚Ìu thaÌ‚Ì€u roÌ£Ì‚ng raÌƒi  \n",
       "1  ThoÌ‚ng tin veÌ‚Ì€ keÌ‚Ìt quaÌ‰ thuÌ›Ì£c hieÌ£Ì‚n hoÌ›Ì£p...  \n",
       "2  LuÌ›Ì£a choÌ£n nhaÌ€ thaÌ‚Ì€u trong truÌ›oÌ›Ì€ng hoÌ›Ì£p ...  \n",
       "3                                LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u  \n",
       "4  laÌ€ vieÌ£Ì‚c mua truÌ›Ì£c tieÌ‚Ìp haÌ€ng hoÌa, diÌ£ch...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7863c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PhuÌ›oÌ›ng thuÌ›Ìc hai giai Ä‘oaÌ£n moÌ£Ì‚t tuÌi hoÌ‚Ì€ soÌ› Ä‘uÌ›oÌ›Ì£c aÌp duÌ£ng trong truÌ›oÌ›Ì€ng hoÌ›Ì£p naÌ€o?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['question'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a1d5f",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 2. Sinh cÃ¢u tráº£ lá»i tá»« há»‡ thá»‘ng RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cac0d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers and retrieving contexts for evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:22<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Sample of generated results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PhuÌ›oÌ›ng thuÌ›Ìc hai giai Ä‘oaÌ£n moÌ£Ì‚t tuÌi hoÌ‚Ì€...</td>\n",
       "      <td>TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» phÆ°Æ¡ng thá»©c ha...</td>\n",
       "      <td>[3. VÄƒn báº£n Ä‘á»ƒ nghá»‹ phÃª duyá»‡t phÆ°Æ¡ng Ã¡n lá»±a ch...</td>\n",
       "      <td>Ä‘aÌ‚Ìu thaÌ‚Ì€u roÌ£Ì‚ng raÌƒi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...</td>\n",
       "      <td>TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» Nghá»‹ Ä‘á»‹nh hÆ°á»›n...</td>\n",
       "      <td>[Ä‘) Pháº¡m vi cung cáº¥p, yÃªu cáº§u vá» ká»¹ thuáº­t, Ä‘iá»...</td>\n",
       "      <td>ThoÌ‚ng tin veÌ‚Ì€ keÌ‚Ìt quaÌ‰ thuÌ›Ì£c hieÌ£Ì‚n hoÌ›Ì£p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u soÌ‚Ì 22/2023/QH15 ÄieÌ‚Ì€u 2...</td>\n",
       "      <td>TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» Äiá»u 29 cá»§a Lu...</td>\n",
       "      <td>[ChÆ°Æ¡ng X\\nDIEU KHOáº¢N THá»Š HANH\\n\\nÄiá»u 95. Hiá»‡...</td>\n",
       "      <td>LuÌ›Ì£a choÌ£n nhaÌ€ thaÌ‚Ì€u trong truÌ›oÌ›Ì€ng hoÌ›Ì£p ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CaÌ†n cuÌ›Ì phaÌp lyÌ naÌ€o quy Ä‘iÌ£nh veÌ‚Ì€ triÌ€nh...</td>\n",
       "      <td>TÃ´i tÃ¬m tháº¥y cÃ¡c quy Ä‘á»‹nh liÃªn quan Ä‘áº¿n trÃ¬nh,...</td>\n",
       "      <td>[d) PhÃ¢n cÃ´ng viá»‡c chÆ°a Ä‘á»§ Ä‘iá»u kiá»‡n láº­p káº¿ ho...</td>\n",
       "      <td>LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Theo NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu t...</td>\n",
       "      <td>TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» Ä‘á»‹nh nghÄ©a \"mu...</td>\n",
       "      <td>[e) Nhá»¯ng tÃ i liá»‡u phÃ¡t sinh trong quÃ¡ trÃ¬nh s...</td>\n",
       "      <td>laÌ€ vieÌ£Ì‚c mua truÌ›Ì£c tieÌ‚Ìp haÌ€ng hoÌa, diÌ£ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  PhuÌ›oÌ›ng thuÌ›Ìc hai giai Ä‘oaÌ£n moÌ£Ì‚t tuÌi hoÌ‚Ì€...   \n",
       "1  NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u...   \n",
       "2  LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u soÌ‚Ì 22/2023/QH15 ÄieÌ‚Ì€u 2...   \n",
       "3  CaÌ†n cuÌ›Ì phaÌp lyÌ naÌ€o quy Ä‘iÌ£nh veÌ‚Ì€ triÌ€nh...   \n",
       "4  Theo NghiÌ£ Ä‘iÌ£nh huÌ›oÌ›Ìng daÌ‚Ìƒn LuaÌ£Ì‚t ÄaÌ‚Ìu t...   \n",
       "\n",
       "                                    generated_answer  \\\n",
       "0  TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» phÆ°Æ¡ng thá»©c ha...   \n",
       "1  TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» Nghá»‹ Ä‘á»‹nh hÆ°á»›n...   \n",
       "2  TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» Äiá»u 29 cá»§a Lu...   \n",
       "3  TÃ´i tÃ¬m tháº¥y cÃ¡c quy Ä‘á»‹nh liÃªn quan Ä‘áº¿n trÃ¬nh,...   \n",
       "4  TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» Ä‘á»‹nh nghÄ©a \"mu...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [3. VÄƒn báº£n Ä‘á»ƒ nghá»‹ phÃª duyá»‡t phÆ°Æ¡ng Ã¡n lá»±a ch...   \n",
       "1  [Ä‘) Pháº¡m vi cung cáº¥p, yÃªu cáº§u vá» ká»¹ thuáº­t, Ä‘iá»...   \n",
       "2  [ChÆ°Æ¡ng X\\nDIEU KHOáº¢N THá»Š HANH\\n\\nÄiá»u 95. Hiá»‡...   \n",
       "3  [d) PhÃ¢n cÃ´ng viá»‡c chÆ°a Ä‘á»§ Ä‘iá»u kiá»‡n láº­p káº¿ ho...   \n",
       "4  [e) Nhá»¯ng tÃ i liá»‡u phÃ¡t sinh trong quÃ¡ trÃ¬nh s...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0                           Ä‘aÌ‚Ìu thaÌ‚Ì€u roÌ£Ì‚ng raÌƒi  \n",
       "1  ThoÌ‚ng tin veÌ‚Ì€ keÌ‚Ìt quaÌ‰ thuÌ›Ì£c hieÌ£Ì‚n hoÌ›Ì£p...  \n",
       "2  LuÌ›Ì£a choÌ£n nhaÌ€ thaÌ‚Ì€u trong truÌ›oÌ›Ì€ng hoÌ›Ì£p ...  \n",
       "3                                LuaÌ£Ì‚t ÄaÌ‚Ìu thaÌ‚Ì€u  \n",
       "4  laÌ€ vieÌ£Ì‚c mua truÌ›Ì£c tieÌ‚Ìp haÌ€ng hoÌa, diÌ£ch...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Láº¥y má»™t máº«u nhá» cá»§a bá»™ test Ä‘á»ƒ cháº¡y nhanh hÆ¡n (vÃ­ dá»¥: 20 máº«u)\n",
    "# Báº¡n cÃ³ thá»ƒ tÄƒng sá»‘ lÆ°á»£ng nÃ y Ä‘á»ƒ cÃ³ káº¿t quáº£ Ä‘Ã¡nh giÃ¡ chÃ­nh xÃ¡c hÆ¡n\n",
    "test_sample = test.head(15)\n",
    "\n",
    "results = []\n",
    "print(\"Generating answers and retrieving contexts for evaluation...\")\n",
    "for index, row in tqdm(test_sample.iterrows(), total=test_sample.shape[0]):\n",
    "    question = row['question']\n",
    "\n",
    "    # Láº¥y káº¿t quáº£ tá»« RAG system\n",
    "    qa_result = rag_system.query(question)\n",
    "    generated_answer = qa_result.get(\"answer\", \"\")\n",
    "\n",
    "    # Truy xuáº¥t láº¡i cÃ¡c context Ä‘áº§y Ä‘á»§ tá»« vector store\n",
    "    retrieved_docs = rag_system.vector_store.similarity_search(question, k=5)\n",
    "    retrieved_contexts = [doc.page_content for doc in retrieved_docs]\n",
    "\n",
    "    results.append({\n",
    "        \"question\": question,\n",
    "        \"generated_answer\": generated_answer,\n",
    "        \"retrieved_contexts\": retrieved_contexts,\n",
    "        \"ground_truth\": row['answer']  # CÃ¢u tráº£ lá»i gá»‘c tá»« dataset\n",
    "    })\n",
    "\n",
    "# Chuyá»ƒn káº¿t quáº£ thÃ nh DataFrame Ä‘á»ƒ dá»… xem\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Done. Sample of generated results:\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7cefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"evaluation_results.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d316851",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"evaluation_results.csv\")\n",
    "results = results_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a720573",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 3. ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng vá»›i RAGAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b49ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import Dataset\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "\n",
    "# --- [PHáº¦N QUAN TRá»ŒNG: Sá»¬ Dá»¤NG WRAPPER Má»šI] ---\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# 1. Kiá»ƒm tra dá»¯ liá»‡u Ä‘áº§u vÃ o (giá»¯ nguyÃªn)\n",
    "if 'results' not in globals() or len(results) == 0:\n",
    "    raise ValueError(\"Danh sÃ¡ch 'results' trá»‘ng. Vui lÃ²ng cháº¡y BÆ°á»›c 2 Ä‘á»ƒ táº¡o káº¿t quáº£.\")\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ or not os.environ[\"GOOGLE_API_KEY\"]:\n",
    "    raise EnvironmentError(\"Thiáº¿u GOOGLE_API_KEY. HÃ£y cáº­p nháº­t file .env vÃ  load láº¡i.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e907a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating with RAGAs (sá»­ dá»¥ng Gemini)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/60 [01:24<?, ?it/s]\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 95, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 646, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 83, in _aresults\n",
      "    raise e\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 78, in _aresults\n",
      "    r = await future\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 125, in ascore\n",
      "    raise e\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 121, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 161, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 570, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 530, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 715, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 581, in _agenerate\n",
      "    response: genai.types.GenerateContentResponse = await _achat_with_retry(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 185, in _achat_with_retry\n",
      "    return await _achat_with_retry(**kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 183, in _achat_with_retry\n",
      "    raise e\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 176, in _achat_with_retry\n",
      "    return await generation_method(**kwargs)\n",
      "TypeError: ChatSession.send_message_async() got an unexpected keyword argument 'temperature'\n",
      "\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 95, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 646, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 83, in _aresults\n",
      "    raise e\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 78, in _aresults\n",
      "    r = await future\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 125, in ascore\n",
      "    raise e\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 121, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 161, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 570, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 530, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 715, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 581, in _agenerate\n",
      "    response: genai.types.GenerateContentResponse = await _achat_with_retry(\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 185, in _achat_with_retry\n",
      "    return await _achat_with_retry(**kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 183, in _achat_with_retry\n",
      "    raise e\n",
      "  File \"e:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 176, in _achat_with_retry\n",
      "    return await generation_method(**kwargs)\n",
      "TypeError: ChatSession.send_message_async() got an unexpected keyword argument 'temperature'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m ragas_embeddings \u001b[38;5;241m=\u001b[39m LangchainEmbeddingsWrapper(gemini_embeddings)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 5. Cháº¡y Ä‘Ã¡nh giÃ¡\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mragas_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mragas_llm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Truyá»n wrapper vÃ o Ä‘Ã¢y\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mragas_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Truyá»n wrapper vÃ o Ä‘Ã¢y\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_precision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_recall\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluation results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(score)\n",
      "File \u001b[1;32me:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\evaluation.py:230\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[0;32m    227\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;241m==\u001b[39m []:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "File \u001b[1;32me:\\Individual\\ChatBot\\law_chatbot\\.venv\\lib\\site-packages\\ragas\\executor.py:131\u001b[0m, in \u001b[0;36mExecutor.results\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m executor_job\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[43mexecutor_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2. Chuáº©n bá»‹ Dataset\n",
    "ragas_dataset_dict = {\n",
    "    'question': [str(r['question']) for r in results],\n",
    "    'answer': [str(r['generated_answer']) for r in results],\n",
    "    'contexts': [[str(ctx) for ctx in r['retrieved_contexts']] for r in results],\n",
    "    'ground_truth': [str(r['ground_truth']) for r in results]\n",
    "}\n",
    "ragas_dataset = Dataset.from_dict(ragas_dataset_dict)\n",
    "\n",
    "print(\"\\nEvaluating with RAGAs (sá»­ dá»¥ng Gemini)...\")\n",
    "\n",
    "# 3. Khá»Ÿi táº¡o LangChain Model & Embeddings (giá»¯ nguyÃªn)\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    model=os.getenv(\"GOOGLE_CHAT_MODEL\", \"gemini-2.0-flash\"),\n",
    "    temperature=0.0,\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    ")\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=os.getenv(\"GOOGLE_EMBEDDING_MODEL\", \"models/embedding-001\"),\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    ")\n",
    "\n",
    "# 4. [Sá»¬A Lá»–I] Bá»c (Wrap) chÃºng láº¡i Ä‘á»ƒ Ragas hiá»ƒu\n",
    "ragas_llm = LangchainLLMWrapper(gemini_llm)\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(gemini_embeddings)\n",
    "\n",
    "# 5. Cháº¡y Ä‘Ã¡nh giÃ¡\n",
    "score = evaluate(\n",
    "    ragas_dataset,\n",
    "    llm=ragas_llm,              # Truyá»n wrapper vÃ o Ä‘Ã¢y\n",
    "    embeddings=ragas_embeddings, # Truyá»n wrapper vÃ o Ä‘Ã¢y\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation results:\")\n",
    "print(score)\n",
    "score_df = score.to_pandas()\n",
    "print(score_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5cfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94a4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
